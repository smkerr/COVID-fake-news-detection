{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"politifact.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyMqS6yvRLYBAeJBWrBF5Ufo"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"tpm4GJzuJpow"},"outputs":[],"source":["#this script scrapes fake news from politifact.com "]},{"cell_type":"code","source":["#Import the dependencies\n","from bs4 import BeautifulSoup\n","import pandas as pd\n","import requests\n","import urllib.request\n","import time"],"metadata":{"id":"8tJDoo9IM6O6","executionInfo":{"status":"ok","timestamp":1650378131123,"user_tz":-120,"elapsed":628,"user":{"displayName":"Hannah Schweren","userId":"17418859482307087546"}}},"execution_count":1,"outputs":[]},{"cell_type":"code","source":["#Create lists to store the scraped data\n","authors = []\n","dates = []\n","statements = []\n","sources = []\n","targets = []"],"metadata":{"id":"urxgBn38NAT7","executionInfo":{"status":"ok","timestamp":1650378150541,"user_tz":-120,"elapsed":245,"user":{"displayName":"Hannah Schweren","userId":"17418859482307087546"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["#Create a function to scrape the site\n","def scrape_website(page_number):\n","  page_num = str(page_number) #Convert the page number to a string\n","  URL = 'https://www.politifact.com/factchecks/list/?page=2&category=coronavirus&ruling=false'+page_num #append the page number to complete the URL\n","  webpage = requests.get(URL)  #Make a request to the website\n","  #time.sleep(3)\n","  soup = BeautifulSoup(webpage.text, \"html.parser\") #Parse the text from the website\n","  #Get the tags and it's class\n","  statement_footer =  soup.find_all('footer',attrs={'class':'m-statement__footer'})  #Get the tag and it's class\n","  statement_quote = soup.find_all('div', attrs={'class':'m-statement__quote'}) #Get the tag and it's class\n","  statement_meta = soup.find_all('div', attrs={'class':'m-statement__meta'})#Get the tag and it's class\n","  target = soup.find_all('div', attrs={'class':'m-statement__meter'}) #Get the tag and it's class\n","  #loop through the footer class m-statement__footer to get the date and author\n","  for i in statement_footer:\n","    link1 = i.text.strip()\n","    name_and_date = link1.split()\n","    first_name = name_and_date[1]\n","    last_name = name_and_date[2]\n","    full_name = first_name+' '+last_name\n","    month = name_and_date[4]\n","    day = name_and_date[5]\n","    year = name_and_date[6]\n","    date = month+' '+day+' '+year\n","    dates.append(date)\n","    authors.append(full_name)\n","  #Loop through the div m-statement__quote to get the link\n","  for i in statement_quote:\n","    link2 = i.find_all('a')\n","    statements.append(link2[0].text.strip())\n"," #Loop through the div m-statement__meta to get the source\n","  for i in statement_meta:\n","    link3 = i.find_all('a') #Source\n","    source_text = link3[0].text.strip()\n","    sources.append(source_text)\n","  #Loop through the target or the div m-statement__meter to get the facts about the statement (True or False)\n","  for i in target:\n","    fact = i.find('div', attrs={'class':'c-image'}).find('img').get('alt')\n","    targets.append(fact)\n","Loop through ’n-1’ number of pages to scrape the data.\n","#Loop through 'n-1' webpages to scrape the data\n","n=101\n","for i in range(1, n):\n","  scrape_website(i)\n","Create and show the data frame to store the data.\n","#Create a new dataFrame \n","data = pd.DataFrame(columns = ['author',  'statement', 'source', 'date', 'target']) \n","data['author'] = authors\n","data['statement'] = statements\n","data['source'] = sources\n","data['date'] = dates\n","data['target'] = targets\n","#Show the data set\n","data\n","\n","Create a function to get convert the target data to a binary number.\n","#Create a function to get a binary number from the target\n","def getBinaryNumTarget(text):\n","  if text == 'true':\n","    return 1\n","  else:\n","    return 0\n","Create a function to get only the true and false values from the target.\n","#Create a function to get only true or false values from the target\n","def getBinaryTarget(text):\n","  if text == 'true':\n","    return 'REAL'\n","  else:\n","    return 'FAKE'\n","Store the data in the data frame.\n","#Store the data in the dataframe\n","data['BinaryTarget'] = data['target'].apply(getBinaryTarget)\n","data['BinaryNumTarget'] = data['target'].apply(getBinaryNumTarget)\n","Show the data.\n","#Show the data\n","data\n","\n","Store the data to a csv file.\n","#Store the data to a CSV file\n","data.to_csv('political_fact_checker.csv')\n","\n","Thanks for reading this article I hope it’s helpful to you all! If you enjoyed this article and found it helpful please leave some claps to show your appreciation. Keep up the learning, and if you like machine learning, mathematics, computer science, programming or algorithm analysis, please visit and subscribe to my YouTube channels (randerson112358 & compsci112358 ).\n","\n"],"metadata":{"id":"0g8QTpsmNFBE"},"execution_count":null,"outputs":[]}]}